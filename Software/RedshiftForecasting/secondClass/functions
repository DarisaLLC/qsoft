### functions for classification



removeErrors = function(data1){
	# identify which are "error" features
	neg = grep("*_negerr", names(data1))
	pos = grep("*_poserr", names(data1))
	errors = c(neg,pos)
	errors = errors[order(errors)]
	errors = 1:length(data1) %in% errors


	# remove the errors, for now
	data1 = subset(data1,select = !errors)
	
	return(data1)
}





# generates k equally sized disjoint sets containing the numbers 1 through len
findFolds = function(len,k){
	sets = list()
	indices = 1:len
	base = floor( len / k )
	left = len %% k 
	for( i in 1:left ){
		sets[[i]] = sample(indices,base + 1)
		indices = indices[!(indices %in% sets[[i]])]
	}
	for( i in (left + 1):k ){
		sets[[i]] = sample(indices,base)
		indices = indices[!(indices %in% sets[[i]])]

	}
	return(sets)
}


confusionAndMisses = function(datagrb,weights,test){
	confusion = matrix(0,nrow=2,ncol=2)
	train = !(1:nrow(datagrb) %in% test)
	test = (1:nrow(datagrb) %in% test)	
	fit = rpart(Z ~ ., subset = train,weights=weights,data=datagrb)
	predictions = predict(fit,type='class',newdata=datagrb)
	
	confusion[1,1] = sum(1*(predictions == "L" & predictions == datagrb$Z & test == T))
	confusion[1,2] = sum(1*(predictions == "L" & predictions != datagrb$Z & test == T))
	confusion[2,1] = sum(1*(predictions == "H" & predictions != datagrb$Z & test == T))
	confusion[2,2] = sum(1*(predictions == "H" & predictions == datagrb$Z & test == T))
	
	highaslow = predictions == "L" & (predictions != datagrb$Z) & test == T

	return(list(highaslow,confusion,fit))	

}

confusionMatrix = function(datagrb,weights,nfold){
	# split up data for cross validation (done randomly)
	sets = findFolds(nrow(datagrb),nfold)
	# initialize confusion matrix, indicator for highs misclassified as lows
	highErrorsCV = rep(FALSE,nrow(datagrb))
	confusion = matrix(0,nrow=2,ncol=2)
	# initialize importance measure for each feature
	importance = data.frame( names(data1)[2:length(data1)] , 0 )
	names(importance) = c("Feature","Counts")

	for(i in 1:nfold){
		# get the info by calling another function
		out1 = confusionAndMisses(datagrb,weights,sets[[i]])		

		# compute confusion and which high were classified as low
		highErrorsCV = highErrorsCV | out1[[1]]
		confusion = confusion + out1[[2]]		

		# compute importances
		varsUsed = out1[[3]]$frame[,1]
		varsUsed = varsUsed[varsUsed!="<leaf>"]
		importance[,2] = importance[,2] + (importance$Feature %in% varsUsed)
	}
	return(list(highErrorsCV,confusion,importance))
}
	

# turns a 2,2,n into a dataframe with means for each cell
# in 2x2 matrices, also includes 5th percentile and 95th
# percentile
confusionDisplay = function(confusionMat){
	outTable = matrix(0,nrow=2,ncol=2)
	outTable = data.frame(outTable)
	for(i in 1:2){
		for(j in 1:2){
			outTable[i,j] = paste(round(mean(confusionMat[i,j,]),2)," (",quantile(confusionMat[i,j,],.05),",",quantile(confusionMat[i,j,],.95),")",sep="")
		}
	}
	return(outTable)
}


# datagrb should have columns as features AND a column Z which is numeric redshift
# Z > CUTOFF ==> high redshift
# COST = cost of classifying high as low (low as high cost is 1)
# nameTree is the name of the output pdf for printing the tree, should end in .pdf
# DESCRIPTION of FUNCTION: 
#
grbTree = function(datagrb,CUTOFF,COST,nameTree,treeTitle,nCV){

	# define high redshift as > CUTOFF
	redshift = rep("L",nrow(datagrb))
	redshift[datagrb$Z > CUTOFF] = "H"
	datagrb$Z = as.factor(redshift)

	# what should be the relative misclassification costs be
	weights = rep(1,nrow(datagrb))
	weights[datagrb$Z == "H"] = COST

	# fit the tree to the entire data, (misclass rates optimistic)
	fit = rpart(Z ~ .,data=datagrb,weights=weights)

	# print the entire tree
#	pdf(nameTree)
#	plot(fit,margin=.1,main=treeTitle)
#	text(fit,use.n=T,pretty=0)
#	dev.off()

	# CROSS VALIDATION
	# now we perform cross validation nCV times in order to get honest estimates of test error  
	# and measures of variable importance

	# initialize location for holding feature importance for CV
	importance = data.frame( names(data1)[2:length(data1)] , 0 )
	names(importance) = c("Feature","Frequency")
	
	# initialize location for holding loss data
	loss = rep(0,nCV)
	confusionMat = array(0,dim=c(2,2,nCV))

	# get information from CV - number of times each feature is used, CV error estimate
	for(i in 1:nCV){
		confusion = confusionMatrix(datagrb,weights,10)
		importance[,2] = importance[,2] + confusion[[3]][,2]
		confusionMat[,,i] = confusion[[2]]
		# compute loss from confusion matrix
		lossPRE = sum(c(confusion[[2]][1,2],confusion[[2]][2,1]) * c(1,COST))
		loss[i] = round(lossPRE / sum(colSums(confusion[[2]]) * c(1, COST)),3)
	}
	return(list(fit,importance,loss,confusionMat))
}


# takes output list from grbTree and produces pretty output - loss and confusionMat
grbTreePretty = function(thetree){
	# get loss looking nice
	loss = thetree[[3]]
	meanLoss = round(mean(loss),2)
	lowerLoss = round(quantile(loss,.05),2)
	upperLoss = round(quantile(loss,.95),2)
	loss = paste(meanLoss," ","(",lowerLoss,",",upperLoss,")",sep="")

	# get confusionMat
	confusionMat = confusionDisplay(thetree[[4]])

	# get variable importance looking nice
	varImp = thetree[[2]]
	varImp[,"Frequency"] = round(varImp[,"Frequency"] / sum(varImp[,"Frequency"]),2)
	varImp = varImp[order(varImp[,2],decreasing=T),]
	varImp = varImp[varImp$Frequency > 0,]

	return(list(loss,confusionMat,varImp))
}



